{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "import math\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "from collections import Counter,defaultdict\n",
    "import pickle\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "# Combining all indexes into one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FREQ - CORPUSINFO - TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inverted indexes\n",
    "ii_freq_imdb = pickle.load( open( \"data-imdb-invertedIndexFreq.pickle\", \"rb\" ) )\n",
    "ii_freq_tmz = pickle.load( open( \"data-tmz-invertedIndexFreq.pickle\", \"rb\" ) )\n",
    "ii_freq_mw = pickle.load( open( \"data-mw-invertedIndexFreq.pickle\", \"rb\" ) )\n",
    "ii_freq_rr = pickle.load( open( \"data-rr-invertedIndexFreq.pickle\", \"rb\" ) )\n",
    "ii_freq_hl = pickle.load( open( \"data-hl-invertedIndexFreq.pickle\", \"rb\" ) )\n",
    "ii_freq_rt = pickle.load( open( \"data-rt-invertedIndexFreq.pickle\", \"rb\" ) )\n",
    "\n",
    "# Initialize final frequency index dict \n",
    "ii_freq_merged = defaultdict(Counter)\n",
    "\n",
    "# Merge indexes\n",
    "for k,v in chain(ii_freq_imdb.items(), ii_freq_tmz.items(), \n",
    "                 ii_freq_mw.items(), ii_freq_rr.items(),\n",
    "                 ii_freq_hl.items(), ii_freq_rt.items()):\n",
    "    \n",
    "    ii_freq_merged[k].update(v)\n",
    "    \n",
    "# Storing the corpus info\n",
    "with open('merged-invertedIndexFreq', 'wb') as handle:\n",
    "    pickle.dump(ii_freq_merged, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load corpus infos\n",
    "ci_imdb = pickle.load( open( \"data-imdb-corpusInfo.pickle\", \"rb\" ) )\n",
    "ci_tmz = pickle.load( open( \"data-tmz-corpusInfo.pickle\", \"rb\" ) )\n",
    "ci_mw = pickle.load( open( \"data-mw-corpusInfo.pickle\", \"rb\" ) )\n",
    "ci_rr = pickle.load( open( \"data-rr-corpusInfo.pickle\", \"rb\" ) )\n",
    "ci_hl = pickle.load( open( \"data-hl-corpusInfo.pickle\", \"rb\" ) )\n",
    "ci_rt = pickle.load( open( \"data-rt-corpusInfo.pickle\", \"rb\" ) )\n",
    "\n",
    "# Initialize final courpusinfo dict\n",
    "ci_merged = ci_imdb\n",
    "\n",
    "# Merge indexes\n",
    "ci_merged['num_docs'] += ci_tmz['num_docs'] \n",
    "for doc, length in ci_tmz['doc_lengths'].items():\n",
    "    ci_merged['doc_lengths'][doc] = length\n",
    "      \n",
    "ci_merged['num_docs'] += ci_mw['num_docs'] \n",
    "for doc, length in ci_mw['doc_lengths'].items():\n",
    "    ci_merged['doc_lengths'][doc] = length\n",
    "    \n",
    "ci_merged['num_docs'] += ci_rr['num_docs'] \n",
    "for doc, length in ci_rr['doc_lengths'].items():\n",
    "    ci_merged['doc_lengths'][doc] = length\n",
    "        \n",
    "ci_merged['num_docs'] += ci_hl['num_docs'] \n",
    "for doc, length in ci_hl['doc_lengths'].items():\n",
    "    ci_merged['doc_lengths'][doc] = length\n",
    "    \n",
    "ci_merged['num_docs'] += ci_rt['num_docs'] \n",
    "for doc, length in ci_rt['doc_lengths'].items():\n",
    "    ci_merged['doc_lengths'][doc] = length\n",
    "    \n",
    "# Storing the corpus info\n",
    "with open('merged-corpusInfo.pickle', 'wb') as handle:\n",
    "    pickle.dump(ci_merged, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute tf-idf\n",
    "def tfidf(doc_freq, doc_length, n_docs_total, n_docs_containing):\n",
    "    return (doc_freq / doc_length) * math.log(n_docs_total / (1 + n_docs_containing))\n",
    "\n",
    "# Load merged files\n",
    "ii_freq_merged = pickle.load( open( \"merged-invertedIndexFreq.pickle\", \"rb\" ) )\n",
    "ci_merged = pickle.load( open( \"merged-corpusInfo.pickle\", \"rb\" ) )\n",
    "\n",
    "# Initialize final weights index dict \n",
    "ii_w_merged = defaultdict(Counter)\n",
    "\n",
    "for w,wv in ii_freq_merged.items():\n",
    "    n_docs_total = ci_merged['num_docs']\n",
    "    n_docs_containing = len(wv)\n",
    "    \n",
    "    for d_id,dv in wv.items():\n",
    "        doc_freq = dv\n",
    "        doc_length = ci_merged['doc_lengths'][d_id]\n",
    "        \n",
    "        ii_w_merged[w][d_id] = tfidf(doc_freq, doc_length, n_docs_total, n_docs_containing)\n",
    "        \n",
    "# Storing the corpus info\n",
    "with open('merged-invertedIndexWeights.pickle', 'wb') as handle:\n",
    "    pickle.dump(ii_w_merged, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POSITIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inverted indexes\n",
    "ii_pos_imdb = pickle.load( open( \"data-imdb-invertedIndexPos.pickle\", \"rb\" ) )\n",
    "ii_pos_tmz = pickle.load( open( \"data-tmz-invertedIndexPos.pickle\", \"rb\" ) )\n",
    "ii_pos_mw = pickle.load( open( \"data-mw-invertedIndexPos.pickle\", \"rb\" ) )\n",
    "ii_pos_rr = pickle.load( open( \"data-rr-invertedIndexPos.pickle\", \"rb\" ) )\n",
    "ii_pos_hl = pickle.load( open( \"data-hl-invertedIndexPos.pickle\", \"rb\" ) )\n",
    "ii_pos_rt = pickle.load( open( \"data-rt-invertedIndexPos.pickle\", \"rb\" ) )\n",
    "\n",
    "# Initialize final position index dict \n",
    "ii_pos_merged = ii_pos_imdb\n",
    "\n",
    "# Merge indexes\n",
    "for w, dic in ii_pos_tmz.items():\n",
    "    for doc, lis in dic.items():\n",
    "        ii_pos_merged[w][doc] = lis\n",
    "        \n",
    "for w, dic in ii_pos_mw.items():\n",
    "    for doc, lis in dic.items():\n",
    "        ii_pos_merged[w][doc] = lis\n",
    "        \n",
    "for w, dic in ii_pos_rr.items():\n",
    "    for doc, lis in dic.items():\n",
    "        ii_pos_merged[w][doc] = lis\n",
    "        \n",
    "for w, dic in ii_pos_hl.items():\n",
    "    for doc, lis in dic.items():\n",
    "        ii_pos_merged[w][doc] = lis\n",
    "        \n",
    "for w, dic in ii_pos_rt.items():\n",
    "    for doc, lis in dic.items():\n",
    "        ii_pos_merged[w][doc] = lis\n",
    "        \n",
    "# Storing the corpus info\n",
    "with open('merged-invertedIndexPos.pickle', 'wb') as handle:\n",
    "    pickle.dump(ii_pos_merged, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
