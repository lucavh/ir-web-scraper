{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "import math\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from collections import Counter,defaultdict\n",
    "import pickle\n",
    "from itertools import chain\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# DEFS ----------------------------------------------------------------------------------------------------\n",
    "def load_data(file):\n",
    "    \n",
    "    with open(file) as f:\n",
    "        json_block = []\n",
    "        for line in f:\n",
    "            json_block.append(json.loads(line))\n",
    "            \n",
    "    return pd.DataFrame(json_block)\n",
    "\n",
    "def tokenize(text):\n",
    "    return [re.sub(r'[^\\w\\s]','',w) for w in nltk.word_tokenize(text.lower()) if re.sub(r'[^\\w\\s]','',w) != '']\n",
    "   \n",
    "def remove_stopwords(tokens):\n",
    "    en_stopwords = set(stopwords.words('english'))\n",
    "    return [word for word in tokens if word not in en_stopwords]\n",
    "\n",
    "def stemmer(tokens):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    return [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "def process_filmography(filmography_object):\n",
    "    filmography = []\n",
    "    for item in filmography_object:\n",
    "        movie_instance = {}\n",
    "        soup = BeautifulSoup(item, 'html.parser')\n",
    "        movie_instance['url'] = 'https://www.imdb.com' + soup.b.a.get('href')\n",
    "        movie_instance['title'] = soup.b.a.get_text()\n",
    "        movie_instance['data'] = ' '.join(soup.get_text().strip().replace('\\n',' ').split(' '))\n",
    "        filmography.append(movie_instance)\n",
    "    \n",
    "    return filmography\n",
    "    \n",
    "def retrieve_relative_news_collection(name, filmography):\n",
    "    list_terms = [name]\n",
    "    list_terms += [movie[\"title\"] for movie in filmography][:3]\n",
    "    \n",
    "    result = {}\n",
    "    relative_urls = []\n",
    "    relative_text = ''\n",
    "    \n",
    "    for index, row in news.iterrows():\n",
    "        for term in list_terms:\n",
    "            if (term.lower() in row.title.lower()) or (term.lower() in row.content.lower()):\n",
    "                relative_urls.append(row.url)\n",
    "                relative_text = relative_text + ' ' + row.title + ' ' + row.content\n",
    "                \n",
    "    result['urls'] = list(set(relative_urls))\n",
    "    result['text'] = relative_text\n",
    "    return result\n",
    "\n",
    "def create_inv_indexes(df):\n",
    "    invertedIndexFreq = defaultdict(Counter)\n",
    "    invertedIndexPos = defaultdict(dict)\n",
    "    corpusInfo = defaultdict(dict)\n",
    "    \n",
    "    corpusInfo['num_docs'] = df.shape[0]\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        corpusInfo['doc_lengths'][row['url']] = len(row['tokenized'])\n",
    "        \n",
    "        for w in row['tokenized']:\n",
    "            invertedIndexFreq[w][row['url']]+=1\n",
    "            invertedIndexPos[w][row['url']] = [i for i, j in enumerate(row['tokenized']) if w == j]\n",
    "            \n",
    "    return invertedIndexFreq, invertedIndexPos, corpusInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD ----------------------------------------------------------------------------------------------------\n",
    "actors_jl = '../data/actors.jl'\n",
    "movies_jl = '../data/movies.jl'\n",
    "tmz_jl = '../data/news_tmz.jl'\n",
    "hollywoodlife_jl = '../data/news_hollywoodlife.jl'\n",
    "movieweb_jl = '../data/news_movieweb.jl'\n",
    "\n",
    "actors = load_data(actors_jl)\n",
    "movies = load_data(movies_jl)\n",
    "tmz = load_data(tmz_jl)\n",
    "hollywoodlife = load_data(hollywoodlife_jl)\n",
    "movieweb = load_data(movieweb_jl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESS -----------------------------------------------------------------------------------------------\n",
    "actors['filmography'] = actors.apply(lambda row: process_filmography(row.filmography), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actors['movie_urls'] = actors.apply(lambda row: ['https://www.imdb.com' + url for url in row.movie_urls], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['tokenized'] = movies.apply(lambda row: stemmer(remove_stopwords(tokenize(row.title + ' ' + row.year + ' ' + ' '.join(row.genres) + ' ' + ' '.join(row.reviews)))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmz['tokenized'] = tmz.apply(lambda row: stemmer(remove_stopwords(tokenize(row.title + ' ' + row.content))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hollywoodlife['tokenized'] = hollywoodlife.apply(lambda row: stemmer(remove_stopwords(tokenize(row.title + ' ' + row.content))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieweb['tokenized'] = movieweb.apply(lambda row: stemmer(remove_stopwords(tokenize(row.title + ' ' + row.content))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((9100, 5), (10484, 5), (11980, 5))\n"
     ]
    }
   ],
   "source": [
    "print(tmz.shape, hollywoodlife.shape, movieweb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31564, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = tmz.append(hollywoodlife)\n",
    "news = news.append(movieweb)\n",
    "news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATCH ------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-6832daf47d3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mactors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'news'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretrieve_relative_news_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"filmography\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[1;32m   4875\u001b[0m                         \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4876\u001b[0m                         \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4877\u001b[0;31m                         ignore_failures=ignore_failures)\n\u001b[0m\u001b[1;32m   4878\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4879\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_apply_standard\u001b[0;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[1;32m   4931\u001b[0m                     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_agg_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4932\u001b[0m                     result = lib.reduce(values, func, axis=axis, dummy=dummy,\n\u001b[0;32m-> 4933\u001b[0;31m                                         labels=labels)\n\u001b[0m\u001b[1;32m   4934\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4935\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/reduce.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.reduce\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/reduce.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.Reducer.get_result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-70-6832daf47d3c>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mactors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'news'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretrieve_relative_news_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"filmography\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-63-fc2c1287917f>\u001b[0m in \u001b[0;36mretrieve_relative_news_collection\u001b[0;34m(name, filmography)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mlist_terms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mlist_terms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmovie\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmovie\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilmography\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfind_relative_news\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_terms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#rel_news_urls = [item for l in news[news.url.isin(find_relative_news('naomi scott'))].url.values for item in l]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-fc2c1287917f>\u001b[0m in \u001b[0;36mfind_relative_news\u001b[0;34m(list_terms)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mrelative_urls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0mrelative_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelative_text\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelative_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelative_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "actors['news'] = actors.apply(lambda row: retrieve_relative_news_collection(row[\"name\"],row[\"filmography\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors['movies'] = actors.apply(lambda row: retrieve_relative_news_collection(row[\"name\"],row[\"filmography\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relative_movie_collection(filmography):\n",
    "    list_movies = [movie[\"title\"] for movie in filmography][:10]\n",
    "    \n",
    "    movies[movies[\"title\"].isin(list_movies)]\n",
    "    relative_urls = []\n",
    "    relative_text = ''\n",
    "    for index, row in news.iterrows():\n",
    "        for term in list_terms:\n",
    "            if (term.lower() in row.title.lower()) or (term.lower() in row.content.lower()):\n",
    "                relative_urls.append(row.url)\n",
    "                relative_text = relative_text + ' ' + row.title + ' ' + row.content\n",
    "    return list(set(relative_urls)), relative_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>reviews</th>\n",
       "      <th>title</th>\n",
       "      <th>url_imdb</th>\n",
       "      <th>url_img</th>\n",
       "      <th>url_metacritic</th>\n",
       "      <th>url_rottom</th>\n",
       "      <th>year</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Animation, Adventure, Adventure, Drama, Family]</td>\n",
       "      <td>[No consensus yet., \\n                        ...</td>\n",
       "      <td>Call of the Wild</td>\n",
       "      <td>https://www.imdb.com/title/tt7504726/?ref_=nm_...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.metacritic.com/movie/call-of-the-wild</td>\n",
       "      <td>https://www.rottentomatoes.com/m/call_of_the_wild</td>\n",
       "      <td>2019</td>\n",
       "      <td>[call, wild, 2019, anim, adventur, adventur, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Drama, Fantasy, Romance, Drama, Romance]</td>\n",
       "      <td>[The Age of Adaline  ruminates on mortality le...</td>\n",
       "      <td>The Age of Adaline</td>\n",
       "      <td>https://www.imdb.com/title/tt1655441/?ref_=nm_...</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMTAzMT...</td>\n",
       "      <td>https://www.metacritic.com/movie/the-age-of-ad...</td>\n",
       "      <td>https://www.rottentomatoes.com/m/the_age_of_ad...</td>\n",
       "      <td>2015</td>\n",
       "      <td>[age, adalin, 2015, drama, fantasi, romanc, dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Crime, Drama, Drama]</td>\n",
       "      <td>[Crossing Over  is flagrant and heavy-handed a...</td>\n",
       "      <td>Crossing Over</td>\n",
       "      <td>https://www.imdb.com/title/tt0924129/?ref_=nm_...</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMjAyMD...</td>\n",
       "      <td>https://www.metacritic.com/movie/crossing-over</td>\n",
       "      <td>https://www.rottentomatoes.com/m/crossing_over</td>\n",
       "      <td>2009</td>\n",
       "      <td>[cross, 2009, crime, drama, drama, cross, flag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Action, Comedy, Crime, Action, Thriller, Come...</td>\n",
       "      <td>[Hollywood Homicide suffers from too many subp...</td>\n",
       "      <td>Hollywood Homicide</td>\n",
       "      <td>https://www.imdb.com/title/tt0329717/?ref_=nm_...</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMTU5Mj...</td>\n",
       "      <td>https://www.metacritic.com/movie/hollywood-hom...</td>\n",
       "      <td>https://www.rottentomatoes.com/m/hollywood_hom...</td>\n",
       "      <td>2003</td>\n",
       "      <td>[hollywood, homicid, 2003, action, comedi, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Drama, Mystery, Sci-Fi, Sci-Fi, Drama, Myster...</td>\n",
       "      <td>[Visually stunning and narratively satisfying,...</td>\n",
       "      <td>Blade Runner 2049</td>\n",
       "      <td>https://www.imdb.com/title/tt1856101/?ref_=nm_...</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BNzA1Nj...</td>\n",
       "      <td>https://www.metacritic.com/movie/blade-runner-...</td>\n",
       "      <td>https://www.rottentomatoes.com/m/blade_runner_...</td>\n",
       "      <td>2017</td>\n",
       "      <td>[blade, runner, 2049, 2017, drama, mysteri, sc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              genres  \\\n",
       "0   [Animation, Adventure, Adventure, Drama, Family]   \n",
       "1          [Drama, Fantasy, Romance, Drama, Romance]   \n",
       "2                              [Crime, Drama, Drama]   \n",
       "3  [Action, Comedy, Crime, Action, Thriller, Come...   \n",
       "4  [Drama, Mystery, Sci-Fi, Sci-Fi, Drama, Myster...   \n",
       "\n",
       "                                             reviews               title  \\\n",
       "0  [No consensus yet., \\n                        ...    Call of the Wild   \n",
       "1  [The Age of Adaline  ruminates on mortality le...  The Age of Adaline   \n",
       "2  [Crossing Over  is flagrant and heavy-handed a...       Crossing Over   \n",
       "3  [Hollywood Homicide suffers from too many subp...  Hollywood Homicide   \n",
       "4  [Visually stunning and narratively satisfying,...   Blade Runner 2049   \n",
       "\n",
       "                                            url_imdb  \\\n",
       "0  https://www.imdb.com/title/tt7504726/?ref_=nm_...   \n",
       "1  https://www.imdb.com/title/tt1655441/?ref_=nm_...   \n",
       "2  https://www.imdb.com/title/tt0924129/?ref_=nm_...   \n",
       "3  https://www.imdb.com/title/tt0329717/?ref_=nm_...   \n",
       "4  https://www.imdb.com/title/tt1856101/?ref_=nm_...   \n",
       "\n",
       "                                             url_img  \\\n",
       "0                                               None   \n",
       "1  https://m.media-amazon.com/images/M/MV5BMTAzMT...   \n",
       "2  https://m.media-amazon.com/images/M/MV5BMjAyMD...   \n",
       "3  https://m.media-amazon.com/images/M/MV5BMTU5Mj...   \n",
       "4  https://m.media-amazon.com/images/M/MV5BNzA1Nj...   \n",
       "\n",
       "                                      url_metacritic  \\\n",
       "0  https://www.metacritic.com/movie/call-of-the-wild   \n",
       "1  https://www.metacritic.com/movie/the-age-of-ad...   \n",
       "2     https://www.metacritic.com/movie/crossing-over   \n",
       "3  https://www.metacritic.com/movie/hollywood-hom...   \n",
       "4  https://www.metacritic.com/movie/blade-runner-...   \n",
       "\n",
       "                                          url_rottom  year  \\\n",
       "0  https://www.rottentomatoes.com/m/call_of_the_wild  2019   \n",
       "1  https://www.rottentomatoes.com/m/the_age_of_ad...  2015   \n",
       "2     https://www.rottentomatoes.com/m/crossing_over  2009   \n",
       "3  https://www.rottentomatoes.com/m/hollywood_hom...  2003   \n",
       "4  https://www.rottentomatoes.com/m/blade_runner_...  2017   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [call, wild, 2019, anim, adventur, adventur, d...  \n",
       "1  [age, adalin, 2015, drama, fantasi, romanc, dr...  \n",
       "2  [cross, 2009, crime, drama, drama, cross, flag...  \n",
       "3  [hollywood, homicid, 2003, action, comedi, cri...  \n",
       "4  [blade, runner, 2049, 2017, drama, mysteri, sc...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INDEX ------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# TODO: CREATE INVERTED INDEX - FREQ ACTOR\n",
    "# TODO: CREATE INVERTED INDEX - POS ACTOR\n",
    "# TODO: CREATE INVERTED INDEX - WEIGHT ACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT ------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# TODO: SAVE INV INDEX - FREQ AS PICKLE\n",
    "# TODO: SAVE INV INDEX - POS AS PICKLE\n",
    "# TODO: SAVE INV INDEX - WEIGHT AS PICKLE\n",
    "# TODO: SAVE ACTOR DF AS JSON\n",
    "# TODO: SAVE MOVIE DF AS JSON\n",
    "# TODO: SAVE NEWS DF AS JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors['movie_urls'] = actors.apply(lambda row: ['https://www.imdb.com' + url for url in row.movie_urls], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_actor_item(name, bio):\n",
    "    tokenized = []\n",
    "    \n",
    "    rel_news = news[news.url.isin(find_relative_news(name))]\n",
    "    tokenized += [item for l in rel_news.tokenized.values for item in l]\n",
    "    \n",
    "    #rel_movies = \n",
    "    \n",
    "    tokenized += stemmer(remove_stopwords(tokenize(bio)))\n",
    "    \n",
    "    return tokenized\n",
    "\n",
    "actors['tokenized'] = actors.apply(lambda row: tokenize_actor_item(row[\"name\"], row.bio_imdb+' '+row.bio_rottom+' '+row.birthday+' '+row.birthplace), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_filmography(actors.head(1).filmography.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(source[:-5]+'-invertedIndexFreq.pickle', 'wb') as handle:\n",
    "    pickle.dump(invertedIndexFreq, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "with open('../data/movie_urls.txt') as f:\n",
    "    urls = ast.literal_eval(f.readlines()[0])\n",
    "\n",
    "start_urls = ['https://www.imdb.com' + url.strip() for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(actors.head(1).filmography.values[0][0], 'html.parser')\n",
    "soup.b.a.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
